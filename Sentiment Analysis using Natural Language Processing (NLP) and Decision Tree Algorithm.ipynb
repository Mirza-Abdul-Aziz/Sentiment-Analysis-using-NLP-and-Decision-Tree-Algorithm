{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**====================================================================================================================**\n",
    "- **Group Members**<br>\n",
    "    \n",
    "    \n",
    "    - Abdul Aziz ( FA18-BCS-203 )\n",
    "    - Ahmed Bilal Yousaf ( FA18-BCS-189 )\n",
    "\n",
    "- **Submitted To**\n",
    "    \n",
    "    \n",
    "    - Dr. Jawad Shafi\n",
    "\n",
    "- **Section**\n",
    "    \n",
    "    \n",
    "    - D\n",
    "\n",
    "- **Assignment No**\n",
    "    \n",
    "    \n",
    "    - 02\n",
    "\n",
    "**=======================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#1.-Import-Libraries\" data-toc-modified-id=\"1.-Import-Libraries-1\">1. Import Libraries</a></span></li><li><span><a href=\"#2.-Read-train/test-data\" data-toc-modified-id=\"2.-Read-train/test-data-2\">2. Read train/test data</a></span></li><li><span><a href=\"#3.-Understand-data-train/test-data\" data-toc-modified-id=\"3.-Understand-data-train/test-data-3\">3. Understand data train/test data</a></span></li><li><span><a href=\"#4.-Pre-process-Train/Test-Data\" data-toc-modified-id=\"4.-Pre-process-Train/Test-Data-4\">4. Pre-process Train/Test Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.1-Combining-train-and-test-data\" data-toc-modified-id=\"4.1-Combining-train-and-test-data-4.1\">4.1 Combining train and test data</a></span><ul class=\"toc-item\"><li><span><a href=\"#4.1.1-Overview-of-the-combined-data\" data-toc-modified-id=\"4.1.1-Overview-of-the-combined-data-4.1.1\">4.1.1 Overview of the combined data</a></span></li></ul></li><li><span><a href=\"#4.2-Removing-Twitter-Handles(@User)\" data-toc-modified-id=\"4.2-Removing-Twitter-Handles(@User)-4.2\">4.2 Removing Twitter Handles(@User)</a></span></li><li><span><a href=\"#4.3-Removing-Punctuation,-Numbers,-and-Special-Characters\" data-toc-modified-id=\"4.3-Removing-Punctuation,-Numbers,-and-Special-Characters-4.3\">4.3 Removing Punctuation, Numbers, and Special Characters</a></span></li><li><span><a href=\"#4.4-Removing-short-words\" data-toc-modified-id=\"4.4-Removing-short-words-4.4\">4.4 Removing short words</a></span></li><li><span><a href=\"#4.5-Tokenization\" data-toc-modified-id=\"4.5-Tokenization-4.5\">4.5 Tokenization</a></span></li><li><span><a href=\"#4.6-Stemming\" data-toc-modified-id=\"4.6-Stemming-4.6\">4.6 Stemming</a></span></li></ul></li><li><span><a href=\"#5.-Label-Encoding-for-Train/Test-data\" data-toc-modified-id=\"5.-Label-Encoding-for-Train/Test-data-5\">5. Label Encoding for Train/Test data</a></span><ul class=\"toc-item\"><li><span><a href=\"#5.1-Train-Data-Encoding\" data-toc-modified-id=\"5.1-Train-Data-Encoding-5.1\">5.1 Train Data Encoding</a></span></li><li><span><a href=\"#5.2-Test-Data-Encoding\" data-toc-modified-id=\"5.2-Test-Data-Encoding-5.2\">5.2 Test Data Encoding</a></span></li><li><span><a href=\"#5.3-Combined-Data-Label-Encoding\" data-toc-modified-id=\"5.3-Combined-Data-Label-Encoding-5.3\">5.3 Combined Data Label Encoding</a></span></li></ul></li><li><span><a href=\"#6.-Feature-extraction-(Changing-representation-of-data—from-string-to-feature-vector).-Apply-following-baseline-features:-bag-of-words,-TF-IDF,-and-word-count.\" data-toc-modified-id=\"6.-Feature-extraction-(Changing-representation-of-data—from-string-to-feature-vector).-Apply-following-baseline-features:-bag-of-words,-TF-IDF,-and-word-count.-6\">6. Feature extraction (Changing representation of data—from string to feature-vector). Apply following baseline features: bag-of-words, TF-IDF, and word count.</a></span><ul class=\"toc-item\"><li><span><a href=\"#6.1-Bag-of-Words-Features\" data-toc-modified-id=\"6.1-Bag-of-Words-Features-6.1\">6.1 Bag-of-Words Features</a></span></li><li><span><a href=\"#6.2-TF-IDF-Features\" data-toc-modified-id=\"6.2-TF-IDF-Features-6.2\">6.2 TF-IDF Features</a></span></li></ul></li><li><span><a href=\"#Bag-of-Words-Features\" data-toc-modified-id=\"Bag-of-Words-Features-7\">Bag-of-Words Features</a></span></li><li><span><a href=\"#7.-Splitting-the-data-into-Input-Vectors-and-Labels\" data-toc-modified-id=\"7.-Splitting-the-data-into-Input-Vectors-and-Labels-8\">7. Splitting the data into Input Vectors and Labels</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.1-Splitting-the-data-into-training-and-validation-data-and-also-the-input-vectors-and-labels\" data-toc-modified-id=\"7.1-Splitting-the-data-into-training-and-validation-data-and-also-the-input-vectors-and-labels-8.1\">7.1 Splitting the data into training and validation data and also the input vectors and labels</a></span></li></ul></li><li><span><a href=\"#8.-Train-decision-tree-machine-learning-algorithms-using-training-data\" data-toc-modified-id=\"8.-Train-decision-tree-machine-learning-algorithms-using-training-data-9\">8. Train decision tree machine learning algorithms using training data</a></span><ul class=\"toc-item\"><li><span><a href=\"#8.1-Save-the-Trained-Model\" data-toc-modified-id=\"8.1-Save-the-Trained-Model-9.1\">8.1 Save the Trained Model</a></span></li></ul></li><li><span><a href=\"#9.-Evaluate-decision-tree-machine-learning-algorithm-using-test-data\" data-toc-modified-id=\"9.-Evaluate-decision-tree-machine-learning-algorithm-using-test-data-10\">9. Evaluate decision tree machine learning algorithm using test data</a></span><ul class=\"toc-item\"><li><span><a href=\"#9.1-Load-the-Trained-Model\" data-toc-modified-id=\"9.1-Load-the-Trained-Model-10.1\">9.1 Load the Trained Model</a></span></li><li><span><a href=\"#9.2-Make-predictions-of-Validation-on-BOW-features-Trained-Model\" data-toc-modified-id=\"9.2-Make-predictions-of-Validation-on-BOW-features-Trained-Model-10.2\">9.2 Make predictions of Validation on BOW features Trained Model</a></span></li><li><span><a href=\"#9.3-Calculte-Accuracy-Score\" data-toc-modified-id=\"9.3-Calculte-Accuracy-Score-10.3\">9.3 Calculte Accuracy Score</a></span></li></ul></li><li><span><a href=\"#TF-IDF-features\" data-toc-modified-id=\"TF-IDF-features-11\">TF-IDF features</a></span></li><li><span><a href=\"#7.-Splitting-the-data-into-Input-Vectors-and-Labels\" data-toc-modified-id=\"7.-Splitting-the-data-into-Input-Vectors-and-Labels-12\">7. Splitting the data into Input Vectors and Labels</a></span><ul class=\"toc-item\"><li><span><a href=\"#7.1-Splitting-the-data-into-training-and-validation-data-and-also-the-input-vectors-and-labels\" data-toc-modified-id=\"7.1-Splitting-the-data-into-training-and-validation-data-and-also-the-input-vectors-and-labels-12.1\">7.1 Splitting the data into training and validation data and also the input vectors and labels</a></span></li></ul></li><li><span><a href=\"#8.-Train-decision-tree-machine-learning-algorithms-using-training-data\" data-toc-modified-id=\"8.-Train-decision-tree-machine-learning-algorithms-using-training-data-13\">8. Train decision tree machine learning algorithms using training data</a></span><ul class=\"toc-item\"><li><span><a href=\"#8.1-Save-the-Trained-Model\" data-toc-modified-id=\"8.1-Save-the-Trained-Model-13.1\">8.1 Save the Trained Model</a></span></li></ul></li><li><span><a href=\"#9.-Evaluate-decision-tree-machine-learning-algorithm-using-test-data\" data-toc-modified-id=\"9.-Evaluate-decision-tree-machine-learning-algorithm-using-test-data-14\">9. Evaluate decision tree machine learning algorithm using test data</a></span><ul class=\"toc-item\"><li><span><a href=\"#9.1-Load-the-Trained-Model\" data-toc-modified-id=\"9.1-Load-the-Trained-Model-14.1\">9.1 Load the Trained Model</a></span></li><li><span><a href=\"#9.2-Make-predictions-of-Validation-on-TFIDF-features-Trained-Model\" data-toc-modified-id=\"9.2-Make-predictions-of-Validation-on-TFIDF-features-Trained-Model-14.2\">9.2 Make predictions of Validation on TFIDF features Trained Model</a></span></li><li><span><a href=\"#9.3-Calculte-Accuracy-Score\" data-toc-modified-id=\"9.3-Calculte-Accuracy-Score-14.3\">9.3 Calculte Accuracy Score</a></span></li></ul></li><li><span><a href=\"#10.-Application-Phase\" data-toc-modified-id=\"10.-Application-Phase-15\">10. Application Phase</a></span><ul class=\"toc-item\"><li><span><a href=\"#10.1:-Take-Input-from-User\" data-toc-modified-id=\"10.1:-Take-Input-from-User-15.1\">10.1: Take Input from User</a></span></li><li><span><a href=\"#10.2-Pre-process-Train/Test-Data\" data-toc-modified-id=\"10.2-Pre-process-Train/Test-Data-15.2\">10.2 Pre-process Train/Test Data</a></span></li><li><span><a href=\"#10.3-Removing-Punctuation,-Numbers,-and-Special-Characters\" data-toc-modified-id=\"10.3-Removing-Punctuation,-Numbers,-and-Special-Characters-15.3\">10.3 Removing Punctuation, Numbers, and Special Characters</a></span></li><li><span><a href=\"#10.4-Removing-short-words\" data-toc-modified-id=\"10.4-Removing-short-words-15.4\">10.4 Removing short words</a></span></li><li><span><a href=\"#10.5-Tokenization\" data-toc-modified-id=\"10.5-Tokenization-15.5\">10.5 Tokenization</a></span></li><li><span><a href=\"#10.6-Stemming\" data-toc-modified-id=\"10.6-Stemming-15.6\">10.6 Stemming</a></span></li></ul></li><li><span><a href=\"#11.-Convert-user-input-into-feature-vector-(same-as-feature-vector-of-trained-model)\" data-toc-modified-id=\"11.-Convert-user-input-into-feature-vector-(same-as-feature-vector-of-trained-model)-16\">11. Convert user input into feature vector (same as feature vector of trained model)</a></span><ul class=\"toc-item\"><li><span><a href=\"#11.1-TF-IDF-Features\" data-toc-modified-id=\"11.1-TF-IDF-Features-16.1\">11.1 TF-IDF Features</a></span></li><li><span><a href=\"#11.2-Load-the-Trained-Model\" data-toc-modified-id=\"11.2-Load-the-Trained-Model-16.2\">11.2 Load the Trained Model</a></span></li><li><span><a href=\"#11.3-Make-predictions-of-Validation-on-TFIDF-features-Trained-Model\" data-toc-modified-id=\"11.3-Make-predictions-of-Validation-on-TFIDF-features-Trained-Model-16.3\">11.3 Make predictions of Validation on TFIDF features Trained Model</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "import nltk\n",
    "from nltk import TweetTokenizer\n",
    "from nltk import PorterStemmer\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Read train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Polarity\n",
       "0             time to eat with my best buddy! #lunch    Happy\n",
       "1  @user @user if they want reflection money. #ksleg    Happy\n",
       "2  ---Good job but I’ will expect a lot more in f...    Happy\n",
       "3  totally dissatisfied with the service###%%@@ n...      Sad\n",
       "4                                 loved my work!!!!!    Happy\n",
       "5        Worst customer care service......@@$$$angry      Sad\n",
       "6                           Brilliant effort guys!!!    Happy\n",
       "7  @user @user you point one finger @user million...      Sad\n",
       "8  words r free, it's how u use that can cost you...    Happy\n",
       "9  you might be a libtard if... #libtard #sjw #li...      Sad"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"train.csv\", header = None)\n",
    "train.columns = [\"Comment\", \"Polarity\"]\n",
    "train_original = train.copy()\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@user the pic says otherwise for young girls c...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment Polarity\n",
       "0  @user the pic says otherwise for young girls c...      Sad\n",
       "1    #good night! ?? #faith ever #vaitacacommafiasdv    Happy\n",
       "2  @user when you're blocked by a troll because y...      Sad\n",
       "3                               dinner with sister!!    Happy\n",
       "4   who else is planning on watching @user tomorrow?    Happy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\", header = None)\n",
    "test.columns = [\"Comment\", \"Polarity\"]\n",
    "test_original = test.copy()\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Understand data train/test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Attributes in Sample Data:\n",
      "==========================\n",
      "\n",
      "Index(['Comment', 'Polarity'], dtype='object')\n",
      "\n",
      "\n",
      "Number of Instances in Train Data: 10\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "Attributes in Test Data:\n",
      "==========================\n",
      "\n",
      "Index(['Comment', 'Polarity'], dtype='object')\n",
      "\n",
      "\n",
      "Number of Instances in Test Data: 5\n",
      "========================================\n",
      "\n",
      "\n",
      "\n",
      "Total Number of Instances in Data: 15\n",
      "========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Understand Train Data\n",
    "\n",
    "print(\"\\n\\nAttributes in Sample Data:\")\n",
    "print(\"==========================\\n\")\n",
    "\n",
    "print(train.columns)\n",
    "\n",
    "print(\"\\n\\nNumber of Instances in Train Data:\",train[\"Polarity\"].count())\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "# Understand Test Data\n",
    "\n",
    "print(\"\\n\\nAttributes in Test Data:\")\n",
    "print(\"==========================\\n\")\n",
    "\n",
    "print(train.columns)\n",
    "\n",
    "print(\"\\n\\nNumber of Instances in Test Data:\",test[\"Polarity\"].count())\n",
    "print(\"========================================\\n\")\n",
    "\n",
    "print(\"\\n\\nTotal Number of Instances in Data:\",train[\"Polarity\"].count() + test[\"Polarity\"].count())\n",
    "print(\"========================================\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Pre-process Train/Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Combining train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = train.append(test,ignore_index=True,sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Overview of the combined data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@user the pic says otherwise for young girls c...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>Happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment Polarity\n",
       "0              time to eat with my best buddy! #lunch    Happy\n",
       "1   @user @user if they want reflection money. #ksleg    Happy\n",
       "2   ---Good job but I’ will expect a lot more in f...    Happy\n",
       "3   totally dissatisfied with the service###%%@@ n...      Sad\n",
       "4                                  loved my work!!!!!    Happy\n",
       "5         Worst customer care service......@@$$$angry      Sad\n",
       "6                            Brilliant effort guys!!!    Happy\n",
       "7   @user @user you point one finger @user million...      Sad\n",
       "8   words r free, it's how u use that can cost you...    Happy\n",
       "9   you might be a libtard if... #libtard #sjw #li...      Sad\n",
       "10  @user the pic says otherwise for young girls c...      Sad\n",
       "11    #good night! ?? #faith ever #vaitacacommafiasdv    Happy\n",
       "12  @user when you're blocked by a troll because y...      Sad\n",
       "13                               dinner with sister!!    Happy\n",
       "14   who else is planning on watching @user tomorrow?    Happy"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Removing Twitter Handles(@User)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tidy_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>if they want reflection money. #ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>totally dissatisfied with the service###%% nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>loved my work!!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "      <td>Worst customer care service......$$$angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>you point one finger  millions are pointed r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@user the pic says otherwise for young girls c...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>the pic says otherwise for young girls confin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>when you're blocked by a troll because you pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>dinner with sister!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>Happy</td>\n",
       "      <td>who else is planning on watching  tomorrow?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment Polarity  \\\n",
       "0              time to eat with my best buddy! #lunch    Happy   \n",
       "1   @user @user if they want reflection money. #ksleg    Happy   \n",
       "2   ---Good job but I’ will expect a lot more in f...    Happy   \n",
       "3   totally dissatisfied with the service###%%@@ n...      Sad   \n",
       "4                                  loved my work!!!!!    Happy   \n",
       "5         Worst customer care service......@@$$$angry      Sad   \n",
       "6                            Brilliant effort guys!!!    Happy   \n",
       "7   @user @user you point one finger @user million...      Sad   \n",
       "8   words r free, it's how u use that can cost you...    Happy   \n",
       "9   you might be a libtard if... #libtard #sjw #li...      Sad   \n",
       "10  @user the pic says otherwise for young girls c...      Sad   \n",
       "11    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
       "12  @user when you're blocked by a troll because y...      Sad   \n",
       "13                               dinner with sister!!    Happy   \n",
       "14   who else is planning on watching @user tomorrow?    Happy   \n",
       "\n",
       "                                         Tidy_Comment  \n",
       "0              time to eat with my best buddy! #lunch  \n",
       "1               if they want reflection money. #ksleg  \n",
       "2   ---Good job but I’ will expect a lot more in f...  \n",
       "3   totally dissatisfied with the service###%% nev...  \n",
       "4                                  loved my work!!!!!  \n",
       "5           Worst customer care service......$$$angry  \n",
       "6                            Brilliant effort guys!!!  \n",
       "7     you point one finger  millions are pointed r...  \n",
       "8   words r free, it's how u use that can cost you...  \n",
       "9   you might be a libtard if... #libtard #sjw #li...  \n",
       "10   the pic says otherwise for young girls confin...  \n",
       "11    #good night! ?? #faith ever #vaitacacommafiasdv  \n",
       "12   when you're blocked by a troll because you pr...  \n",
       "13                               dinner with sister!!  \n",
       "14        who else is planning on watching  tomorrow?  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_pattern(comment, pattern):\n",
    "#     r = re.findall(pattern, comment)\n",
    "#     for i in r:\n",
    "    comment = re.sub(pattern,\"\", comment)\n",
    "    return comment\n",
    "combined_data[\"Tidy_Comment\"] = np.vectorize(remove_pattern)(combined_data[\"Comment\"], \"@[\\w]*\")\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Removing Punctuation, Numbers, and Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tidy_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "      <td>time to eat with my best buddy #lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>if they want reflection money #ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Good job but I will expect a lot more in future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>totally dissatisfied with the service### never...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>loved my work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "      <td>Worst customer care serviceangry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Brilliant effort guys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>you point one finger  millions are pointed r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>words r free its how u use that can cost you #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>you might be a libtard if #libtard #sjw #liber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@user the pic says otherwise for young girls c...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>the pic says otherwise for young girls confin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "      <td>#good night  #faith ever #vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>when youre blocked by a troll because you pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>Happy</td>\n",
       "      <td>who else is planning on watching  tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment Polarity  \\\n",
       "0              time to eat with my best buddy! #lunch    Happy   \n",
       "1   @user @user if they want reflection money. #ksleg    Happy   \n",
       "2   ---Good job but I’ will expect a lot more in f...    Happy   \n",
       "3   totally dissatisfied with the service###%%@@ n...      Sad   \n",
       "4                                  loved my work!!!!!    Happy   \n",
       "5         Worst customer care service......@@$$$angry      Sad   \n",
       "6                            Brilliant effort guys!!!    Happy   \n",
       "7   @user @user you point one finger @user million...      Sad   \n",
       "8   words r free, it's how u use that can cost you...    Happy   \n",
       "9   you might be a libtard if... #libtard #sjw #li...      Sad   \n",
       "10  @user the pic says otherwise for young girls c...      Sad   \n",
       "11    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
       "12  @user when you're blocked by a troll because y...      Sad   \n",
       "13                               dinner with sister!!    Happy   \n",
       "14   who else is planning on watching @user tomorrow?    Happy   \n",
       "\n",
       "                                         Tidy_Comment  \n",
       "0               time to eat with my best buddy #lunch  \n",
       "1                if they want reflection money #ksleg  \n",
       "2     Good job but I will expect a lot more in future  \n",
       "3   totally dissatisfied with the service### never...  \n",
       "4                                       loved my work  \n",
       "5                    Worst customer care serviceangry  \n",
       "6                               Brilliant effort guys  \n",
       "7     you point one finger  millions are pointed r...  \n",
       "8   words r free its how u use that can cost you #...  \n",
       "9   you might be a libtard if #libtard #sjw #liber...  \n",
       "10   the pic says otherwise for young girls confin...  \n",
       "11       #good night  #faith ever #vaitacacommafiasdv  \n",
       "12   when youre blocked by a troll because you pro...  \n",
       "13                                 dinner with sister  \n",
       "14         who else is planning on watching  tomorrow  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data[\"Tidy_Comment\"] = combined_data[\"Tidy_Comment\"].str.replace(\"[^a-zA-Z#\\s]\", \"\")\n",
    "combined_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Removing short words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tidy_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "      <td>time with best buddy #lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>they want reflection money #ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Good will expect more future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>totally dissatisfied with service### never use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>loved work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "      <td>Worst customer care serviceangry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>Brilliant effort guys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>point finger millions pointed right back #jewi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>words free that cost #verbal #abuse #love #adu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>might libtard #libtard #sjw #liberal #politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@user the pic says otherwise for young girls c...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>says otherwise young girls confined that kitch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "      <td>#good night #faith ever #vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>when youre blocked troll because promise #blac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>Happy</td>\n",
       "      <td>else planning watching tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment Polarity  \\\n",
       "0              time to eat with my best buddy! #lunch    Happy   \n",
       "1   @user @user if they want reflection money. #ksleg    Happy   \n",
       "2   ---Good job but I’ will expect a lot more in f...    Happy   \n",
       "3   totally dissatisfied with the service###%%@@ n...      Sad   \n",
       "4                                  loved my work!!!!!    Happy   \n",
       "5         Worst customer care service......@@$$$angry      Sad   \n",
       "6                            Brilliant effort guys!!!    Happy   \n",
       "7   @user @user you point one finger @user million...      Sad   \n",
       "8   words r free, it's how u use that can cost you...    Happy   \n",
       "9   you might be a libtard if... #libtard #sjw #li...      Sad   \n",
       "10  @user the pic says otherwise for young girls c...      Sad   \n",
       "11    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
       "12  @user when you're blocked by a troll because y...      Sad   \n",
       "13                               dinner with sister!!    Happy   \n",
       "14   who else is planning on watching @user tomorrow?    Happy   \n",
       "\n",
       "                                         Tidy_Comment  \n",
       "0                         time with best buddy #lunch  \n",
       "1                   they want reflection money #ksleg  \n",
       "2                        Good will expect more future  \n",
       "3   totally dissatisfied with service### never use...  \n",
       "4                                          loved work  \n",
       "5                    Worst customer care serviceangry  \n",
       "6                               Brilliant effort guys  \n",
       "7   point finger millions pointed right back #jewi...  \n",
       "8   words free that cost #verbal #abuse #love #adu...  \n",
       "9      might libtard #libtard #sjw #liberal #politics  \n",
       "10  says otherwise young girls confined that kitch...  \n",
       "11        #good night #faith ever #vaitacacommafiasdv  \n",
       "12  when youre blocked troll because promise #blac...  \n",
       "13                                 dinner with sister  \n",
       "14                    else planning watching tomorrow  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['Tidy_Comment'] = combined_data['Tidy_Comment'].apply(\n",
    "    lambda x: ' '.join([w for w in x.split() if len(w) > 3]))\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tidy_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[time, with, best, buddy, #lunch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[they, want, reflection, money, #ksleg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[Good, will, expect, more, future]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[totally, dissatisfied, with, service, #, #, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[loved, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[Worst, customer, care, serviceangry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[Brilliant, effort, guys]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[point, finger, millions, pointed, right, back...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[words, free, that, cost, #verbal, #abuse, #lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[might, libtard, #libtard, #sjw, #liberal, #po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@user the pic says otherwise for young girls c...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[says, otherwise, young, girls, confined, that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[#good, night, #faith, ever, #vaitacacommafiasdv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[when, youre, blocked, troll, because, promise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[dinner, with, sister]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[else, planning, watching, tomorrow]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment Polarity  \\\n",
       "0              time to eat with my best buddy! #lunch    Happy   \n",
       "1   @user @user if they want reflection money. #ksleg    Happy   \n",
       "2   ---Good job but I’ will expect a lot more in f...    Happy   \n",
       "3   totally dissatisfied with the service###%%@@ n...      Sad   \n",
       "4                                  loved my work!!!!!    Happy   \n",
       "5         Worst customer care service......@@$$$angry      Sad   \n",
       "6                            Brilliant effort guys!!!    Happy   \n",
       "7   @user @user you point one finger @user million...      Sad   \n",
       "8   words r free, it's how u use that can cost you...    Happy   \n",
       "9   you might be a libtard if... #libtard #sjw #li...      Sad   \n",
       "10  @user the pic says otherwise for young girls c...      Sad   \n",
       "11    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
       "12  @user when you're blocked by a troll because y...      Sad   \n",
       "13                               dinner with sister!!    Happy   \n",
       "14   who else is planning on watching @user tomorrow?    Happy   \n",
       "\n",
       "                                         Tidy_Comment  \n",
       "0                   [time, with, best, buddy, #lunch]  \n",
       "1             [they, want, reflection, money, #ksleg]  \n",
       "2                  [Good, will, expect, more, future]  \n",
       "3   [totally, dissatisfied, with, service, #, #, #...  \n",
       "4                                       [loved, work]  \n",
       "5               [Worst, customer, care, serviceangry]  \n",
       "6                           [Brilliant, effort, guys]  \n",
       "7   [point, finger, millions, pointed, right, back...  \n",
       "8   [words, free, that, cost, #verbal, #abuse, #lo...  \n",
       "9   [might, libtard, #libtard, #sjw, #liberal, #po...  \n",
       "10  [says, otherwise, young, girls, confined, that...  \n",
       "11  [#good, night, #faith, ever, #vaitacacommafiasdv]  \n",
       "12  [when, youre, blocked, troll, because, promise...  \n",
       "13                             [dinner, with, sister]  \n",
       "14               [else, planning, watching, tomorrow]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tokenizer = TweetTokenizer()\n",
    "combined_data[\"Tidy_Comment\"] = combined_data['Tidy_Comment'].apply(lambda x: Tokenizer.tokenize(str(x)))\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.6 Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tidy_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[time, with, best, buddi, #lunch]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[they, want, reflect, money, #ksleg]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[good, will, expect, more, futur]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[total, dissatisfi, with, servic, #, #, #, nev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[love, work]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[worst, custom, care, serviceangri]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[brilliant, effort, guy]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[point, finger, million, point, right, back, #...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[word, free, that, cost, #verbal, #abus, #love...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[might, libtard, #libtard, #sjw, #liber, #polit]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@user the pic says otherwise for young girls c...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[say, otherwis, young, girl, confin, that, kit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[#good, night, #faith, ever, #vaitacacommafiasdv]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>[when, your, block, troll, becaus, promis, #bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[dinner, with, sister]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>Happy</td>\n",
       "      <td>[els, plan, watch, tomorrow]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment Polarity  \\\n",
       "0              time to eat with my best buddy! #lunch    Happy   \n",
       "1   @user @user if they want reflection money. #ksleg    Happy   \n",
       "2   ---Good job but I’ will expect a lot more in f...    Happy   \n",
       "3   totally dissatisfied with the service###%%@@ n...      Sad   \n",
       "4                                  loved my work!!!!!    Happy   \n",
       "5         Worst customer care service......@@$$$angry      Sad   \n",
       "6                            Brilliant effort guys!!!    Happy   \n",
       "7   @user @user you point one finger @user million...      Sad   \n",
       "8   words r free, it's how u use that can cost you...    Happy   \n",
       "9   you might be a libtard if... #libtard #sjw #li...      Sad   \n",
       "10  @user the pic says otherwise for young girls c...      Sad   \n",
       "11    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
       "12  @user when you're blocked by a troll because y...      Sad   \n",
       "13                               dinner with sister!!    Happy   \n",
       "14   who else is planning on watching @user tomorrow?    Happy   \n",
       "\n",
       "                                         Tidy_Comment  \n",
       "0                   [time, with, best, buddi, #lunch]  \n",
       "1                [they, want, reflect, money, #ksleg]  \n",
       "2                   [good, will, expect, more, futur]  \n",
       "3   [total, dissatisfi, with, servic, #, #, #, nev...  \n",
       "4                                        [love, work]  \n",
       "5                 [worst, custom, care, serviceangri]  \n",
       "6                            [brilliant, effort, guy]  \n",
       "7   [point, finger, million, point, right, back, #...  \n",
       "8   [word, free, that, cost, #verbal, #abus, #love...  \n",
       "9    [might, libtard, #libtard, #sjw, #liber, #polit]  \n",
       "10  [say, otherwis, young, girl, confin, that, kit...  \n",
       "11  [#good, night, #faith, ever, #vaitacacommafiasdv]  \n",
       "12  [when, your, block, troll, becaus, promis, #bl...  \n",
       "13                             [dinner, with, sister]  \n",
       "14                       [els, plan, watch, tomorrow]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "combined_data['Tidy_Comment'] = combined_data['Tidy_Comment'].apply(\n",
    "    lambda comment: [ps.stem(letter) for letter in comment])\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s stitch these tokens back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tidy_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>time to eat with my best buddy! #lunch</td>\n",
       "      <td>Happy</td>\n",
       "      <td>time with best buddi #lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@user @user if they want reflection money. #ksleg</td>\n",
       "      <td>Happy</td>\n",
       "      <td>they want reflect money #ksleg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---Good job but I’ will expect a lot more in f...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>good will expect more futur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>totally dissatisfied with the service###%%@@ n...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>total dissatisfi with servic # # # never use t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loved my work!!!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>love work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Worst customer care service......@@$$$angry</td>\n",
       "      <td>Sad</td>\n",
       "      <td>worst custom care serviceangri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Brilliant effort guys!!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>brilliant effort guy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@user @user you point one finger @user million...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>point finger million point right back #jewishs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>words r free, it's how u use that can cost you...</td>\n",
       "      <td>Happy</td>\n",
       "      <td>word free that cost #verbal #abus #love #adult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>you might be a libtard if... #libtard #sjw #li...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>might libtard #libtard #sjw #liber #polit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@user the pic says otherwise for young girls c...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>say otherwis young girl confin that kitchen vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>#good night! ?? #faith ever #vaitacacommafiasdv</td>\n",
       "      <td>Happy</td>\n",
       "      <td>#good night #faith ever #vaitacacommafiasdv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@user when you're blocked by a troll because y...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>when your block troll becaus promis #blacklive...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dinner with sister!!</td>\n",
       "      <td>Happy</td>\n",
       "      <td>dinner with sister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>who else is planning on watching @user tomorrow?</td>\n",
       "      <td>Happy</td>\n",
       "      <td>els plan watch tomorrow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Comment Polarity  \\\n",
       "0              time to eat with my best buddy! #lunch    Happy   \n",
       "1   @user @user if they want reflection money. #ksleg    Happy   \n",
       "2   ---Good job but I’ will expect a lot more in f...    Happy   \n",
       "3   totally dissatisfied with the service###%%@@ n...      Sad   \n",
       "4                                  loved my work!!!!!    Happy   \n",
       "5         Worst customer care service......@@$$$angry      Sad   \n",
       "6                            Brilliant effort guys!!!    Happy   \n",
       "7   @user @user you point one finger @user million...      Sad   \n",
       "8   words r free, it's how u use that can cost you...    Happy   \n",
       "9   you might be a libtard if... #libtard #sjw #li...      Sad   \n",
       "10  @user the pic says otherwise for young girls c...      Sad   \n",
       "11    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
       "12  @user when you're blocked by a troll because y...      Sad   \n",
       "13                               dinner with sister!!    Happy   \n",
       "14   who else is planning on watching @user tomorrow?    Happy   \n",
       "\n",
       "                                         Tidy_Comment  \n",
       "0                         time with best buddi #lunch  \n",
       "1                      they want reflect money #ksleg  \n",
       "2                         good will expect more futur  \n",
       "3   total dissatisfi with servic # # # never use t...  \n",
       "4                                           love work  \n",
       "5                      worst custom care serviceangri  \n",
       "6                                brilliant effort guy  \n",
       "7   point finger million point right back #jewishs...  \n",
       "8   word free that cost #verbal #abus #love #adult...  \n",
       "9           might libtard #libtard #sjw #liber #polit  \n",
       "10  say otherwis young girl confin that kitchen vo...  \n",
       "11        #good night #faith ever #vaitacacommafiasdv  \n",
       "12  when your block troll becaus promis #blacklive...  \n",
       "13                                 dinner with sister  \n",
       "14                            els plan watch tomorrow  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(combined_data[\"Tidy_Comment\"])):\n",
    "    combined_data[\"Tidy_Comment\"][i] = ' '.join(combined_data[\"Tidy_Comment\"][i])\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Label Encoding for Train/Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Train Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Label Encoder\n",
    "\n",
    "''' \n",
    "*------------------ TRAIN_LABEL_ENCODER --------------------*\n",
    "|        Function: Fit()                                    |\n",
    "|              Purpose: Fit or Train the Label Encoder      |\n",
    "|        Arguments:                                         |\n",
    "|               Labels: Target Values                       |\n",
    "|        Return:                                            |\n",
    "|               Instance: Returns an instance of self       |\n",
    "*-----------------------------------------------------------*\n",
    "''' \n",
    "\n",
    "# Label\n",
    "polarity = pd.DataFrame({\"Polarity\": [\"Happy\", \"Sad\"]})\n",
    "# Initializ the label encoder\n",
    "polarity_label_encoder = LabelEncoder()\n",
    "# Train the Label Encoder\n",
    "polarity_label_encoder.fit(np.ravel(polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_Polarity = train_original.copy()\n",
    "original_train_data = train_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Output Attribute After Label Encoding:\n",
      "========================================\n",
      "\n",
      "  Polarity  Encoded_Polarity\n",
      "0    Happy                 0\n",
      "1    Happy                 0\n",
      "2    Happy                 0\n",
      "3      Sad                 1\n",
      "4    Happy                 0\n",
      "5      Sad                 1\n",
      "6    Happy                 0\n",
      "7      Sad                 1\n",
      "8    Happy                 0\n",
      "9      Sad                 1\n",
      "\n",
      "\n",
      "Original Train Data:\n",
      "=====================\n",
      "\n",
      "                                             Comment Polarity\n",
      "0             time to eat with my best buddy! #lunch    Happy\n",
      "1  @user @user if they want reflection money. #ksleg    Happy\n",
      "2  ---Good job but I’ will expect a lot more in f...    Happy\n",
      "3  totally dissatisfied with the service###%%@@ n...      Sad\n",
      "4                                 loved my work!!!!!    Happy\n",
      "5        Worst customer care service......@@$$$angry      Sad\n",
      "6                           Brilliant effort guys!!!    Happy\n",
      "7  @user @user you point one finger @user million...      Sad\n",
      "8  words r free, it's how u use that can cost you...    Happy\n",
      "9  you might be a libtard if... #libtard #sjw #li...      Sad\n",
      "\n",
      "\n",
      "Train Data after Label Encoding of Output:\n",
      "===========================================\n",
      "\n",
      "                                             Comment Polarity  \\\n",
      "0             time to eat with my best buddy! #lunch    Happy   \n",
      "1  @user @user if they want reflection money. #ksleg    Happy   \n",
      "2  ---Good job but I’ will expect a lot more in f...    Happy   \n",
      "3  totally dissatisfied with the service###%%@@ n...      Sad   \n",
      "4                                 loved my work!!!!!    Happy   \n",
      "5        Worst customer care service......@@$$$angry      Sad   \n",
      "6                           Brilliant effort guys!!!    Happy   \n",
      "7  @user @user you point one finger @user million...      Sad   \n",
      "8  words r free, it's how u use that can cost you...    Happy   \n",
      "9  you might be a libtard if... #libtard #sjw #li...      Sad   \n",
      "\n",
      "   Encoded_Polarity  \n",
      "0                 0  \n",
      "1                 0  \n",
      "2                 0  \n",
      "3                 1  \n",
      "4                 0  \n",
      "5                 1  \n",
      "6                 0  \n",
      "7                 1  \n",
      "8                 0  \n",
      "9                 1  \n"
     ]
    }
   ],
   "source": [
    "# Label Encoding of the Output\n",
    "\n",
    "''' \n",
    "*------------------ LABEL_ENCODE_OUTPUT --------------------*\n",
    "|        Function: Transform()                              |\n",
    "|              Purpose: Transform Input (Categorical)       |\n",
    "|                       into Numerical Representation       |\n",
    "|        Arguments:                                         |\n",
    "|              Attribute: Target values                     |\n",
    "|        Return:                                            |\n",
    "|              Attribute: Numerical Representation          |\n",
    "*-----------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "\n",
    "# Transform Output of into Numerical Representation\n",
    "\n",
    "print(\"\\n\\nOutput Attribute After Label Encoding:\")\n",
    "print(\"========================================\\n\")\n",
    "train[\"Encoded_Polarity\"] = polarity_label_encoder.transform(train['Polarity'])\n",
    "print(train[[\"Polarity\", \"Encoded_Polarity\"]])\n",
    "\n",
    "# Print Original and Encoded Ouput Sample Data\n",
    "\n",
    "train_encoded_polarity = train\n",
    "print(\"\\n\\nOriginal Train Data:\")\n",
    "print(\"=====================\\n\")\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(original_train_data)\n",
    "print(\"\\n\\nTrain Data after Label Encoding of Output:\")\n",
    "print(\"===========================================\\n\")\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(train_encoded_polarity)\n",
    "\n",
    "# Save the Transformed Features into CSV File \n",
    "\n",
    "# sample_data_encoded_output.to_csv(r'sample-data-encoded-output.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Test Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Label Encoder\n",
    "\n",
    "''' \n",
    "*------------------ TRAIN_LABEL_ENCODER --------------------*\n",
    "|        Function: Fit()                                    |\n",
    "|              Purpose: Fit or Train the Label Encoder      |\n",
    "|        Arguments:                                         |\n",
    "|               Labels: Target Values                       |\n",
    "|        Return:                                            |\n",
    "|               Instance: Returns an instance of self       |\n",
    "*-----------------------------------------------------------*\n",
    "''' \n",
    "\n",
    "# Label\n",
    "polarity = pd.DataFrame({\"Polarity\": [\"Happy\", \"Sad\"]})\n",
    "# Initializ the label encoder\n",
    "polarity_label_encoder = LabelEncoder()\n",
    "# Train the Label Encoder\n",
    "polarity_label_encoder.fit(np.ravel(polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_encoded_polarity = test_original.copy()\n",
    "original_test_data = test_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Output Attribute After Label Encoding:\n",
      "========================================\n",
      "\n",
      "  Polarity  Encoded_Polarity\n",
      "0      Sad                 1\n",
      "1    Happy                 0\n",
      "2      Sad                 1\n",
      "3    Happy                 0\n",
      "4    Happy                 0\n",
      "\n",
      "\n",
      "Original Test Data:\n",
      "=====================\n",
      "\n",
      "                                             Comment Polarity\n",
      "0  @user the pic says otherwise for young girls c...      Sad\n",
      "1    #good night! ?? #faith ever #vaitacacommafiasdv    Happy\n",
      "2  @user when you're blocked by a troll because y...      Sad\n",
      "3                               dinner with sister!!    Happy\n",
      "4   who else is planning on watching @user tomorrow?    Happy\n",
      "\n",
      "\n",
      "Test Data after Label Encoding of Output:\n",
      "===========================================\n",
      "\n",
      "                                             Comment Polarity  \\\n",
      "0  @user the pic says otherwise for young girls c...      Sad   \n",
      "1    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
      "2  @user when you're blocked by a troll because y...      Sad   \n",
      "3                               dinner with sister!!    Happy   \n",
      "4   who else is planning on watching @user tomorrow?    Happy   \n",
      "\n",
      "   Encoded_Polarity  \n",
      "0                 1  \n",
      "1                 0  \n",
      "2                 1  \n",
      "3                 0  \n",
      "4                 0  \n"
     ]
    }
   ],
   "source": [
    "# Label Encoding of the Output\n",
    "\n",
    "''' \n",
    "*------------------ LABEL_ENCODE_OUTPUT --------------------*\n",
    "|        Function: Transform()                              |\n",
    "|              Purpose: Transform Input (Categorical)       |\n",
    "|                       into Numerical Representation       |\n",
    "|        Arguments:                                         |\n",
    "|              Attribute: Target values                     |\n",
    "|        Return:                                            |\n",
    "|              Attribute: Numerical Representation          |\n",
    "*-----------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Transform Output of into Numerical Representation\n",
    "\n",
    "print(\"\\n\\nOutput Attribute After Label Encoding:\")\n",
    "print(\"========================================\\n\")\n",
    "test[\"Encoded_Polarity\"] = polarity_label_encoder.transform(test['Polarity'])\n",
    "print(test[[\"Polarity\", \"Encoded_Polarity\"]])\n",
    "\n",
    "# Print Original and Encoded Ouput Sample Data\n",
    "\n",
    "test_encoded_polarity = test\n",
    "print(\"\\n\\nOriginal Test Data:\")\n",
    "print(\"=====================\\n\")\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(original_test_data)\n",
    "print(\"\\n\\nTest Data after Label Encoding of Output:\")\n",
    "print(\"===========================================\\n\")\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(test_encoded_polarity)\n",
    "\n",
    "# Save the Transformed Features into CSV File \n",
    "\n",
    "# sample_data_encoded_output.to_csv(r'sample-data-encoded-output.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Combined Data Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Label Encoder\n",
    "\n",
    "''' \n",
    "*------------------ TRAIN_LABEL_ENCODER --------------------*\n",
    "|        Function: Fit()                                    |\n",
    "|              Purpose: Fit or Train the Label Encoder      |\n",
    "|        Arguments:                                         |\n",
    "|               Labels: Target Values                       |\n",
    "|        Return:                                            |\n",
    "|               Instance: Returns an instance of self       |\n",
    "*-----------------------------------------------------------*\n",
    "''' \n",
    "\n",
    "# Label\n",
    "polarity = pd.DataFrame({\"Polarity\": [\"Happy\", \"Sad\"]})\n",
    "# Initializ the label encoder\n",
    "polarity_label_encoder = LabelEncoder()\n",
    "# Train the Label Encoder\n",
    "polarity_label_encoder.fit(np.ravel(polarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data_encoded_polarity = combined_data.copy()\n",
    "original_combined_data = combined_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Output Attribute After Label Encoding:\n",
      "========================================\n",
      "\n",
      "   Polarity  Encoded_Polarity\n",
      "0     Happy                 0\n",
      "1     Happy                 0\n",
      "2     Happy                 0\n",
      "3       Sad                 1\n",
      "4     Happy                 0\n",
      "5       Sad                 1\n",
      "6     Happy                 0\n",
      "7       Sad                 1\n",
      "8     Happy                 0\n",
      "9       Sad                 1\n",
      "10      Sad                 1\n",
      "11    Happy                 0\n",
      "12      Sad                 1\n",
      "13    Happy                 0\n",
      "14    Happy                 0\n",
      "\n",
      "\n",
      "Original Combined Data:\n",
      "=====================\n",
      "\n",
      "                                              Comment Polarity  \\\n",
      "0              time to eat with my best buddy! #lunch    Happy   \n",
      "1   @user @user if they want reflection money. #ksleg    Happy   \n",
      "2   ---Good job but I’ will expect a lot more in f...    Happy   \n",
      "3   totally dissatisfied with the service###%%@@ n...      Sad   \n",
      "4                                  loved my work!!!!!    Happy   \n",
      "5         Worst customer care service......@@$$$angry      Sad   \n",
      "6                            Brilliant effort guys!!!    Happy   \n",
      "7   @user @user you point one finger @user million...      Sad   \n",
      "8   words r free, it's how u use that can cost you...    Happy   \n",
      "9   you might be a libtard if... #libtard #sjw #li...      Sad   \n",
      "10  @user the pic says otherwise for young girls c...      Sad   \n",
      "11    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
      "12  @user when you're blocked by a troll because y...      Sad   \n",
      "13                               dinner with sister!!    Happy   \n",
      "14   who else is planning on watching @user tomorrow?    Happy   \n",
      "\n",
      "                                         Tidy_Comment  \n",
      "0                         time with best buddi #lunch  \n",
      "1                      they want reflect money #ksleg  \n",
      "2                         good will expect more futur  \n",
      "3   total dissatisfi with servic # # # never use t...  \n",
      "4                                           love work  \n",
      "5                      worst custom care serviceangri  \n",
      "6                                brilliant effort guy  \n",
      "7   point finger million point right back #jewishs...  \n",
      "8   word free that cost #verbal #abus #love #adult...  \n",
      "9           might libtard #libtard #sjw #liber #polit  \n",
      "10  say otherwis young girl confin that kitchen vo...  \n",
      "11        #good night #faith ever #vaitacacommafiasdv  \n",
      "12  when your block troll becaus promis #blacklive...  \n",
      "13                                 dinner with sister  \n",
      "14                            els plan watch tomorrow  \n",
      "\n",
      "\n",
      "Combined Data after Label Encoding of Output:\n",
      "===========================================\n",
      "\n",
      "                                              Comment Polarity  \\\n",
      "0              time to eat with my best buddy! #lunch    Happy   \n",
      "1   @user @user if they want reflection money. #ksleg    Happy   \n",
      "2   ---Good job but I’ will expect a lot more in f...    Happy   \n",
      "3   totally dissatisfied with the service###%%@@ n...      Sad   \n",
      "4                                  loved my work!!!!!    Happy   \n",
      "5         Worst customer care service......@@$$$angry      Sad   \n",
      "6                            Brilliant effort guys!!!    Happy   \n",
      "7   @user @user you point one finger @user million...      Sad   \n",
      "8   words r free, it's how u use that can cost you...    Happy   \n",
      "9   you might be a libtard if... #libtard #sjw #li...      Sad   \n",
      "10  @user the pic says otherwise for young girls c...      Sad   \n",
      "11    #good night! ?? #faith ever #vaitacacommafiasdv    Happy   \n",
      "12  @user when you're blocked by a troll because y...      Sad   \n",
      "13                               dinner with sister!!    Happy   \n",
      "14   who else is planning on watching @user tomorrow?    Happy   \n",
      "\n",
      "                                         Tidy_Comment  Encoded_Polarity  \n",
      "0                         time with best buddi #lunch                 0  \n",
      "1                      they want reflect money #ksleg                 0  \n",
      "2                         good will expect more futur                 0  \n",
      "3   total dissatisfi with servic # # # never use t...                 1  \n",
      "4                                           love work                 0  \n",
      "5                      worst custom care serviceangri                 1  \n",
      "6                                brilliant effort guy                 0  \n",
      "7   point finger million point right back #jewishs...                 1  \n",
      "8   word free that cost #verbal #abus #love #adult...                 0  \n",
      "9           might libtard #libtard #sjw #liber #polit                 1  \n",
      "10  say otherwis young girl confin that kitchen vo...                 1  \n",
      "11        #good night #faith ever #vaitacacommafiasdv                 0  \n",
      "12  when your block troll becaus promis #blacklive...                 1  \n",
      "13                                 dinner with sister                 0  \n",
      "14                            els plan watch tomorrow                 0  \n"
     ]
    }
   ],
   "source": [
    "# Label Encoding of the Output\n",
    "\n",
    "''' \n",
    "*------------------ LABEL_ENCODE_OUTPUT --------------------*\n",
    "|        Function: Transform()                              |\n",
    "|              Purpose: Transform Input (Categorical)       |\n",
    "|                       into Numerical Representation       |\n",
    "|        Arguments:                                         |\n",
    "|              Attribute: Target values                     |\n",
    "|        Return:                                            |\n",
    "|              Attribute: Numerical Representation          |\n",
    "*-----------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Transform Output of into Numerical Representation\n",
    "\n",
    "print(\"\\n\\nOutput Attribute After Label Encoding:\")\n",
    "print(\"========================================\\n\")\n",
    "combined_data[\"Encoded_Polarity\"] = polarity_label_encoder.transform(combined_data['Polarity'])\n",
    "print(combined_data[[\"Polarity\", \"Encoded_Polarity\"]])\n",
    "\n",
    "# Print Original and Encoded Ouput Sample Data\n",
    "\n",
    "combined_data_encoded_polarity = combined_data\n",
    "print(\"\\n\\nOriginal Combined Data:\")\n",
    "print(\"=====================\\n\")\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(original_combined_data)\n",
    "print(\"\\n\\nCombined Data after Label Encoding of Output:\")\n",
    "print(\"===========================================\\n\")\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None)\n",
    "print(combined_data_encoded_polarity)\n",
    "\n",
    "# Save the Transformed Features into CSV File \n",
    "\n",
    "# sample_data_encoded_output.to_csv(r'sample-data-encoded-output.csv', index = False, header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Feature extraction (Changing representation of data—from string to feature-vector). Apply following baseline features: bag-of-words, TF-IDF, and word count."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Bag-of-Words Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    good  love\n",
       "0      0     0\n",
       "1      0     0\n",
       "2      1     0\n",
       "3      0     0\n",
       "4      0     1\n",
       "5      0     0\n",
       "6      0     0\n",
       "7      0     0\n",
       "8      0     1\n",
       "9      0     0\n",
       "10     0     0\n",
       "11     1     0\n",
       "12     0     0\n",
       "13     0     0\n",
       "14     0     0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(max_df=0.90,\n",
    "                                   min_df=2,\n",
    "                                   max_features=1000,\n",
    "                                   stop_words='english')\n",
    "\n",
    "# Step 3. Create the Bag-of-Words Model\n",
    "bag_of_words = count_vectorizer.fit_transform(combined_data['Tidy_Comment'])\n",
    "\n",
    "# Show the Bag-of-Words Model as a pandas DataFrame\n",
    "feature_names = count_vectorizer.get_feature_names()\n",
    "pd.DataFrame(bag_of_words.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>good</th>\n",
       "      <th>love</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    good  love\n",
       "0    0.0   0.0\n",
       "1    0.0   0.0\n",
       "2    1.0   0.0\n",
       "3    0.0   0.0\n",
       "4    0.0   1.0\n",
       "5    0.0   0.0\n",
       "6    0.0   0.0\n",
       "7    0.0   0.0\n",
       "8    0.0   1.0\n",
       "9    0.0   0.0\n",
       "10   0.0   0.0\n",
       "11   1.0   0.0\n",
       "12   0.0   0.0\n",
       "13   0.0   0.0\n",
       "14   0.0   0.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.90, min_df=2, stop_words='english')\n",
    "values = tfidf_vectorizer.fit_transform(combined_data['Tidy_Comment'])\n",
    "\n",
    "# Show the Model as a pandas DataFrame\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "pd.DataFrame(values.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 1],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [1, 0],\n",
       "        [0, 0],\n",
       "        [0, 0],\n",
       "        [0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_bow = bag_of_words\n",
    "train_bow.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [1., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tfidf_matrix = values\n",
    "train_tfidf_matrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag-of-Words Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Splitting the data into Input Vectors and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Splitting the data into training and validation data and also the input vectors and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_bow, x_valid_bow, y_train_bow, y_valid_bow = train_test_split(train_bow,combined_data['Encoded_Polarity'],test_size=0.3,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x2 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_valid_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Train decision tree machine learning algorithms using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training the Decision Tree algorithm on Training Data\n",
      "========================================================\n",
      "\n",
      "\n",
      "Parameters and their values:\n",
      "============================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Support Vector Classifier\n",
    "\n",
    "''' \n",
    "*--------------- TRAIN_SUPPORT_VECTOR_CLASSIFIER ------------------*\n",
    "|       Function: DecisionTreeClassifier()                         |\n",
    "|           Purpose: Train the Algorithm on Training Data          |\n",
    "|       Arguments:                                                 |\n",
    "|           Training Data: Provide Training Data to the Model      |\n",
    "|       Return:                                                    |\n",
    "|           Parameter: Model return the Training Parameters        |\n",
    "*------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "print(\"\\n\\nTraining the Decision Tree algorithm on Training Data\")\n",
    "print(\"========================================================\\n\")\n",
    "print(\"\\nParameters and their values:\")\n",
    "print(\"============================\\n\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_bow = DecisionTreeClassifier(criterion='entropy', random_state=1)\n",
    "model_bow.fit(x_train_bow,y_train_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Trained Model\n",
    "\n",
    "''' \n",
    "*--------------------- SAVE_THE_TRAINED_MODEL ---------------------*\n",
    "|        Function: dump()                                          |\n",
    "|             Purpose: Save the Trained Model on your Hard Disk    |\n",
    "|        Arguments:                                                |\n",
    "|             Model: Model Objects                                 |\n",
    "|        Return:                                                   |\n",
    "|             File: Trained Model will be Saved on Hard Disk       |\n",
    "*------------------------------------------------------------------* \n",
    "'''\n",
    "\n",
    "# Save the Model in a Pkl File\n",
    "import pickle\n",
    "pickle.dump(model_bow, open('decision_tree_bow_trained_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Evaluate decision tree machine learning algorithm using test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Saved Model\n",
    "\n",
    "''' \n",
    "*------------------- LOAD_SAVED_MODEL --------------------------*\n",
    "|         Function: load()                                      |\n",
    "|               Purpose: Method to Load Previously Saved Model  |\n",
    "|         Arguments:                                            |\n",
    "|               Model: Trained Model                            |\n",
    "|         Return:                                               |\n",
    "|               File: Saved Model will be Loaded in Memory      |\n",
    "*---------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Load the Saved Model\n",
    "\n",
    "model = pickle.load(open('decision_tree_bow_trained_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Make predictions of Validation on BOW features Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1. , 0. ],\n",
       "       [1. , 0. ],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5],\n",
       "       [0.5, 0.5]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_bow = model.predict_proba(x_valid_bow)\n",
    "\n",
    "dct_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Calculte Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if prediction is greater than or equal to 0.3 than 1 else 0\n",
    "# Where 0 is for positive sentiment tweets and 1 for negative sentiment tweets\n",
    "dct_bow=dct_bow[:,1]>=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11    0\n",
      "4     0\n",
      "5     1\n",
      "0     0\n",
      "9     1\n",
      "Name: Encoded_Polarity, dtype: int32\n",
      "[0 0 1 1 1]\n",
      "\n",
      "\n",
      "Accuracy Score by using BOW Features to make Predictions:\n",
      "===========================================================\n",
      "\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Accuracy Score\n",
    "\n",
    "''' \n",
    "/*------------------------ CALCULATE_ACCURACY_SCORE -------------------*\n",
    "|          Function: accuracy_score()                                  |\n",
    "|                Purpose: Evaluate the algorithm on Testing data       |\n",
    "|          Arguments:                                                  |\n",
    "|                Prediction: Predicted values                          |\n",
    "|                Label: Actual values                                  |\n",
    "|          Return:                                                     |\n",
    "|                Accuracy: Accuracy Score                              |\n",
    "*----------------------------------------------------------------------*\n",
    "'''\n",
    "# converting the results to integer type\n",
    "dct_int_bow=dct_bow.astype(np.int)\n",
    "print(y_valid_bow)\n",
    "print(dct_int_bow)\n",
    "\n",
    "# calculating accuracy score\n",
    "dct_score_bow=accuracy_score(y_valid_bow,dct_int_bow)\n",
    "\n",
    "print(\"\\n\\nAccuracy Score by using BOW Features to make Predictions:\")\n",
    "print(\"===========================================================\\n\")\n",
    "print(dct_score_bow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Splitting the data into Input Vectors and Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Splitting the data into training and validation data and also the input vectors and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tfidf, x_valid_tfidf, y_train_tfidf, y_valid_tfidf = train_test_split(train_tfidf_matrix,combined_data['Encoded_Polarity'],test_size=0.3,random_state=17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Train decision tree machine learning algorithms using training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training the Decision Tree algorithm on Training Data\n",
      "========================================================\n",
      "\n",
      "\n",
      "Parameters and their values:\n",
      "============================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the Support Vector Classifier\n",
    "\n",
    "''' \n",
    "*--------------- TRAIN_SUPPORT_VECTOR_CLASSIFIER ------------------*\n",
    "|       Function: DecisionTreeClassifier()                         |\n",
    "|           Purpose: Train the Algorithm on Training Data          |\n",
    "|       Arguments:                                                 |\n",
    "|           Training Data: Provide Training Data to the Model      |\n",
    "|       Return:                                                    |\n",
    "|           Parameter: Model return the Training Parameters        |\n",
    "*------------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "print(\"\\n\\nTraining the Decision Tree algorithm on Training Data\")\n",
    "print(\"========================================================\\n\")\n",
    "print(\"\\nParameters and their values:\")\n",
    "print(\"============================\\n\")\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model_bow = DecisionTreeClassifier(criterion='entropy', random_state=1)\n",
    "model_bow.fit(x_train_tfidf,y_train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Save the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Trained Model\n",
    "\n",
    "''' \n",
    "*--------------------- SAVE_THE_TRAINED_MODEL ---------------------*\n",
    "|        Function: dump()                                          |\n",
    "|             Purpose: Save the Trained Model on your Hard Disk    |\n",
    "|        Arguments:                                                |\n",
    "|             Model: Model Objects                                 |\n",
    "|        Return:                                                   |\n",
    "|             File: Trained Model will be Saved on Hard Disk       |\n",
    "*------------------------------------------------------------------* \n",
    "'''\n",
    "\n",
    "# Save the Model in a Pkl File\n",
    "import pickle\n",
    "pickle.dump(model_bow, open('decision_tree_tfidf_trained_model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Evaluate decision tree machine learning algorithm using test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Saved Model\n",
    "\n",
    "''' \n",
    "*------------------- LOAD_SAVED_MODEL --------------------------*\n",
    "|         Function: load()                                      |\n",
    "|               Purpose: Method to Load Previously Saved Model  |\n",
    "|         Arguments:                                            |\n",
    "|               Model: Trained Model                            |\n",
    "|         Return:                                               |\n",
    "|               File: Saved Model will be Loaded in Memory      |\n",
    "*---------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Load the Saved Model\n",
    "\n",
    "model = pickle.load(open('decision_tree_tfidf_trained_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Make predictions of Validation on TFIDF features Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.57142857, 0.42857143],\n",
       "       [0.57142857, 0.42857143],\n",
       "       [0.57142857, 0.42857143],\n",
       "       [1.        , 0.        ],\n",
       "       [0.57142857, 0.42857143]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dct_tfidf = model.predict_proba(x_valid_tfidf)\n",
    "\n",
    "dct_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 Calculte Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if prediction is greater than or equal to 0.3 than 1 else 0\n",
    "# Where 0 is for positive sentiment tweets and 1 for negative sentiment tweets\n",
    "dct_tfidf=dct_tfidf[:,1]>=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Accuracy Score by using TFIDF Features to make Predictions:\n",
      "===========================================================\n",
      "\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Accuracy Score\n",
    "\n",
    "''' \n",
    "/*------------------------ CALCULATE_ACCURACY_SCORE -------------------*\n",
    "|          Function: accuracy_score()                                  |\n",
    "|                Purpose: Evaluate the algorithm on Testing data       |\n",
    "|          Arguments:                                                  |\n",
    "|                Prediction: Predicted values                          |\n",
    "|                Label: Actual values                                  |\n",
    "|          Return:                                                     |\n",
    "|                Accuracy: Accuracy Score                              |\n",
    "*----------------------------------------------------------------------*\n",
    "'''\n",
    "# converting the results to integer type\n",
    "dct_int_tfidf=dct_tfidf.astype(np.int)\n",
    "# calculating accuracy score\n",
    "dct_score_tfidf=accuracy_score(y_valid_tfidf,dct_int_tfidf)\n",
    "\n",
    "print(\"\\n\\nAccuracy Score by using TFIDF Features to make Predictions:\")\n",
    "print(\"===========================================================\\n\")\n",
    "print(dct_score_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Application Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.1: Take Input from User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Please enter tweet here : I am very happy and excited to go to Lahore agaian #excited #happy @user1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am very happy and excited to go to Lahore ag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment\n",
       "0  I am very happy and excited to go to Lahore ag..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take Input from User\n",
    "''' \n",
    "---------------- TAKE_USER_INPUT ----------------\n",
    "'''\n",
    "tweet = str(input(\"\\nPlease enter tweet here : \"))\n",
    "user_input = pd.DataFrame({\"Comment\": [tweet]})\n",
    "user_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.2 Pre-process Train/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Tidy_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am very happy and excited to go to Lahore ag...</td>\n",
       "      <td>I am very happy and excited to go to Lahore ag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  I am very happy and excited to go to Lahore ag...   \n",
       "\n",
       "                                        Tidy_Comment  \n",
       "0  I am very happy and excited to go to Lahore ag...  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_pattern(comment, pattern):\n",
    "#     r = re.findall(pattern, comment)\n",
    "#     for i in r:\n",
    "    comment = re.sub(pattern,\"\", comment)\n",
    "    return comment\n",
    "user_input[\"Tidy_Comment\"] = np.vectorize(remove_pattern)(user_input[\"Comment\"], \"@[\\w]*\")\n",
    "user_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.3 Removing Punctuation, Numbers, and Special Characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Tidy_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am very happy and excited to go to Lahore ag...</td>\n",
       "      <td>I am very happy and excited to go to Lahore ag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  I am very happy and excited to go to Lahore ag...   \n",
       "\n",
       "                                        Tidy_Comment  \n",
       "0  I am very happy and excited to go to Lahore ag...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input[\"Tidy_Comment\"] = user_input[\"Tidy_Comment\"].str.replace(\"[^a-zA-Z#\\s]\", \"\")\n",
    "user_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.4 Removing short words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Tidy_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am very happy and excited to go to Lahore ag...</td>\n",
       "      <td>very happy excited Lahore agaian #excited #happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  I am very happy and excited to go to Lahore ag...   \n",
       "\n",
       "                                       Tidy_Comment  \n",
       "0  very happy excited Lahore agaian #excited #happy  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input['Tidy_Comment'] = user_input['Tidy_Comment'].apply(\n",
    "    lambda x: ' '.join([w for w in x.split() if len(w) > 3]))\n",
    "user_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.5 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Tidy_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am very happy and excited to go to Lahore ag...</td>\n",
       "      <td>[very, happy, excited, Lahore, agaian, #excite...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  I am very happy and excited to go to Lahore ag...   \n",
       "\n",
       "                                        Tidy_Comment  \n",
       "0  [very, happy, excited, Lahore, agaian, #excite...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Tokenizer = TweetTokenizer()\n",
    "user_input[\"Tidy_Comment\"] = user_input['Tidy_Comment'].apply(lambda x: Tokenizer.tokenize(str(x)))\n",
    "user_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.6 Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Tidy_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am very happy and excited to go to Lahore ag...</td>\n",
       "      <td>[veri, happi, excit, lahor, agaian, #excit, #h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  I am very happy and excited to go to Lahore ag...   \n",
       "\n",
       "                                        Tidy_Comment  \n",
       "0  [veri, happi, excit, lahor, agaian, #excit, #h...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = PorterStemmer()\n",
    "user_input['Tidy_Comment'] = user_input['Tidy_Comment'].apply(\n",
    "    lambda comment: [ps.stem(letter) for letter in comment])\n",
    "user_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let’s stitch these tokens back together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Tidy_Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am very happy and excited to go to Lahore ag...</td>\n",
       "      <td>veri happi excit lahor agaian #excit #happi</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  \\\n",
       "0  I am very happy and excited to go to Lahore ag...   \n",
       "\n",
       "                                  Tidy_Comment  \n",
       "0  veri happi excit lahor agaian #excit #happi  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(user_input[\"Tidy_Comment\"])):\n",
    "    user_input[\"Tidy_Comment\"][i] = ' '.join(user_input[\"Tidy_Comment\"][i])\n",
    "user_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Convert user input into feature vector (same as feature vector of trained model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.1 TF-IDF Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excit</th>\n",
       "      <th>happi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      excit     happi\n",
       "0  0.707107  0.707107"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_features=2, stop_words='english')\n",
    "values = tfidf_vectorizer.fit_transform(user_input['Tidy_Comment'])\n",
    "\n",
    "# Show the Model as a pandas DataFrame\n",
    "feature_names = tfidf_vectorizer.get_feature_names()\n",
    "pd.DataFrame(values.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.70710678, 0.70710678]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input_tfidf_matrix = values\n",
    "user_input_tfidf_matrix.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.2 Load the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Saved Model\n",
    "\n",
    "''' \n",
    "*------------------- LOAD_SAVED_MODEL --------------------------*\n",
    "|         Function: load()                                      |\n",
    "|               Purpose: Method to Load Previously Saved Model  |\n",
    "|         Arguments:                                            |\n",
    "|               Model: Trained Model                            |\n",
    "|         Return:                                               |\n",
    "|               File: Saved Model will be Loaded in Memory      |\n",
    "*---------------------------------------------------------------*\n",
    "'''\n",
    "\n",
    "# Load the Saved Model\n",
    "\n",
    "model = pickle.load(open('decision_tree_tfidf_trained_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.3 Make predictions of Validation on TFIDF features Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: Happy\n"
     ]
    }
   ],
   "source": [
    "dct_tfidf = model.predict_proba(user_input_tfidf_matrix)\n",
    "dct_tfidf=dct_tfidf[:,1]>=0.5\n",
    "dct_int_tfidf=dct_tfidf.astype(np.int)\n",
    "dct_int_tfidf\n",
    "if dct_int_tfidf == 0:\n",
    "    print(\"Prediction: Happy\")\n",
    "if dct_int_tfidf == 1:\n",
    "    print(\"Prediction: Sad\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
